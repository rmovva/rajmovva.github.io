---
layout: default
---

<img class="profile-picture" src="images/profile.jpg">

Hi, I’m Raj, a CS PhD student at Cornell Tech in New York. I work on responsible AI and computational social science. Recently, I've been thinking about algorithmic fairness, health disparities, and language data -- especially where these topics intersect. I am advised by Prof. Emma Pierson and am supported by an NSF GRFP.

<!-- Advised by Profs. [Emma Pierson](https://www.cs.cornell.edu/~emmapierson/) and [Nikhil Garg](https://gargnikhil.com/), -->

Previously, I studied CS at MIT with minors in Biology and Women’s & Gender Studies. I was lucky to work in the [Data + Feminism Lab](https://dataplusfeminism.mit.edu/), where we developed intersectional, participatory NLP systems to support activist labor ([FAccT 2022](https://dl.acm.org/doi/10.1145/3531146.3533132)). Before that, I worked on efficiency and compression in neural networks, particularly for language models \[[1](https://aclanthology.org/2022.coling-1.252/), [2](https://www.aclweb.org/anthology/2020.blackboxnlp-1.19/), [3](https://arxiv.org/abs/2104.14753)\]. I am very thankful to my excellent mentors along the way, including Dr. Harini Suresh, Dr. Jonathan Frankle, and Shayne Longpre; see [here](https://rajivmovva.com/people) for a list of people I am very indebted to, and please feel free to ask for additional details on why they're so great (e.g. if you're considering working with them).

I hew closely to PhD stereotypes: my primary hobbies are baking, rock climbing, [reading](https://www.goodreads.com/user/show/139600509-rajiv-movva), mixology, and tennis. If you'd like to read some unreliable recipes I've written, see [here](https://rajivmovva.com/recipes).  

### Updates

- [2023-08] I presented our [paper on granular race disparities](https://arxiv.org/abs/2304.09270) at MLHC 2023! Thanks for the excellent conversations; code will be up soon!
- [2023-07] [New working paper](https://arxiv.org/abs/2307.10700) on arXiv! We analyzed 14K language modeling-related papers on arXiv to detail recent publishing trends.
- [2023-04] [Our new paper](https://arxiv.org/abs/2304.09270) is on arXiv, the first from my PhD! We find that granular race categories are critical to algorithmic fairness analyses in healthcare; [here's](https://twitter.com/rajivmovva/status/1651237859465080834) a summary.
- [2022-08] [Our paper](https://arxiv.org/abs/2208.09684) on compressing language models is accepted to COLING 2022! I led this project during an Apple internship in 2021.
<!-- - [2022-04] In the Fall, I'll start my PhD at Cornell Tech in NYC. -->
<!-- - [2022-04] I was awarded an NSF Graduate Fellowship! -->

<!-- Though it's no longer my main interest, I'm also passionate about computational biology, including [functional epigenomics](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0218073) and ligand-protein binding prediction. My favorite hobby is cooking, along with other stereotypical grad student activities: lifting weights, baking, [reading](https://www.goodreads.com/user/show/139600509-rajiv-movva), and playing tennis. You can find some of my [recipes](https://rajivmovva.com/recipes) here (it's a WIP). -->

<!-- While there, I worked with Prof. Catherine D’Ignazio and student Harini Suresh at the [Data + Feminism Lab](https://dataplusfeminism.mit.edu/). Collaborating with activist groups, we co-designed NLP models to support the difficult labor of tracking gender-based violence ([Best Paper, FAccT 2022](https://dl.acm.org/doi/10.1145/3531146.3533132)). The project taught me that naive ML systems often fail at the margins – it takes effort and care to design models for specific, intersectional contexts. -->

<!-- Before that, I explored neural network compression, i.e. improving memory & compute efficiency to mitigate AI’s consumptive footprint. Mentored by Jonathan Frankle, I tested an approach for [parallelized pruning of neural networks](https://arxiv.org/abs/2104.14753). During an internship at Apple, I [combined compression techniques](https://aclanthology.org/2022.coling-1.252/) to rein in the compute footprint of large language models. I also earned Best Paper at BlackboxNLP 2020 for studying how [pruning affects interpretability](https://www.aclweb.org/anthology/2020.blackboxnlp-1.19/) in Transformers.  -->

<!-- Though it's no longer my main interest, I'm also passionate about computational biology, including [functional epigenomics](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0218073) and ligand-protein binding prediction. My favorite hobby is cooking, along with other stereotypical grad student activities: lifting weights, baking, [reading](https://www.goodreads.com/user/show/139600509-rajiv-movva), and playing tennis. You can find some of my [recipes](https://rajivmovva.com/recipes) here (it's a WIP). -->
